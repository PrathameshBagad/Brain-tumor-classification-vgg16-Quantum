{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDp1n7yRwwOs",
        "outputId": "95f511ad-1b00-4620-a408-9807f466e43d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Path to the ZIP file\n",
        "zip_path = '/content/drive/MyDrive/Project/BrainTumorDataset.zip'\n",
        "extract_to = '/content/dataset'\n",
        "\n",
        "# Extract ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# Verify extraction\n",
        "import os\n",
        "print(os.listdir(extract_to))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrFdAcDmxHNm",
        "outputId": "f47635dd-69e1-4aee-8366-2c930c4e5c15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['figshare-brain-tumor-dataset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t0zb5Zyhxy2i",
        "outputId": "9befc242-235f-4217-93a8-b31b5712a940"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.41.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.15.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\n",
            "Collecting tomlkit (from pennylane)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.41 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.41.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.41->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.4.26)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading PennyLane-0.41.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.1-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.41.1-cp311-cp311-manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m114.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, tomlkit, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.1 diastatic-malt-2.15.2 pennylane-0.41.1 pennylane-lightning-0.41.1 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Concatenate\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import pennylane as qml\n",
        "import h5py\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkXcMRkox6rL",
        "outputId": "0be91ffd-120e-4b77-9084-1049d7b8dfab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pennylane/capture/capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.5.2 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "IMG_WIDTH, IMG_HEIGHT = 128, 128\n",
        "NUM_CLASSES = 3\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "N_QUBITS = 8\n",
        "\n",
        "# Utility Functions\n",
        "def load_mat_file_v7_3(filepath):\n",
        "    with h5py.File(filepath, 'r') as file:\n",
        "        label = np.array(file['cjdata']['label']).squeeze()\n",
        "        image = np.array(file['cjdata']['image']).T\n",
        "        tumor_mask = np.array(file['cjdata']['tumorMask']).T\n",
        "        return label, image, tumor_mask\n",
        "\n",
        "def resize_image(image, width, height):\n",
        "    return cv2.resize(image, (width, height))\n"
      ],
      "metadata": {
        "id": "mTWK9yQa2zGv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to dataset\n",
        "dataset_path = '/content/dataset/figshare-brain-tumor-dataset/dataset/data'\n",
        "\n",
        "# Load dataset\n",
        "images, labels = [], []\n",
        "for filename in os.listdir(dataset_path):\n",
        "    if filename.endswith(\".mat\"):\n",
        "        filepath = os.path.join(dataset_path, filename)\n",
        "        label, image, _ = load_mat_file_v7_3(filepath)\n",
        "        resized_image = resize_image(image, IMG_WIDTH, IMG_HEIGHT)\n",
        "        images.append(resized_image)\n",
        "        labels.append(label)\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Normalize and preprocess images\n",
        "images_normalized = images / 255.0\n",
        "images_expanded = np.expand_dims(images_normalized, axis=-1)\n",
        "images_rgb = np.repeat(images_expanded, 3, axis=-1)  # Convert to RGB\n",
        "\n",
        "# One-hot encode labels\n",
        "encoder = LabelBinarizer()\n",
        "labels_encoded = encoder.fit_transform(labels)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(images_rgb, labels_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Eop728CV23kG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "8vFsBzZy263d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantum Circuit for Feature Extraction\n",
        "dev = qml.device(\"default.qubit\", wires=N_QUBITS)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def quantum_circuit(inputs):\n",
        "    for i in range(N_QUBITS):\n",
        "        qml.RX(inputs[i], wires=i)\n",
        "        qml.RY(inputs[i], wires=i)\n",
        "    for i in range(N_QUBITS - 1):\n",
        "        qml.CNOT(wires=[i, i+1])\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(N_QUBITS)]\n",
        "\n",
        "def quantum_feature_extraction(images):\n",
        "    quantum_features = []\n",
        "    for img in images:\n",
        "        flattened = img.flatten()[:N_QUBITS]\n",
        "        q_features = quantum_circuit(flattened)\n",
        "        quantum_features.append(q_features)\n",
        "    return np.array(quantum_features)\n",
        "\n",
        "# Extract Quantum Features\n",
        "X_train_q = quantum_feature_extraction(X_train)\n",
        "X_test_q = quantum_feature_extraction(X_test)"
      ],
      "metadata": {
        "id": "7hlm6IJ14HLf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_combined_model():\n",
        "    # VGG16 Branch\n",
        "    image_input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3), name=\"Image_Input\")\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_tensor=image_input)\n",
        "    for layer in base_model.layers[:-8]:\n",
        "        layer.trainable = False\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    vgg_output = Dense(128, activation='relu')(x)\n",
        "\n",
        "    # Quantum Features Branch\n",
        "    quantum_input = Input(shape=(N_QUBITS,), name=\"Quantum_Input\")\n",
        "    q_x = Dense(64, activation='relu')(quantum_input)\n",
        "    q_output = Dense(32, activation='relu')(q_x)\n",
        "\n",
        "    # Combined Features\n",
        "    combined = Concatenate()([vgg_output, q_output])\n",
        "    final_x = Dense(128, activation='relu')(combined)\n",
        "    final_x = Dropout(0.5)(final_x)\n",
        "    output = Dense(NUM_CLASSES, activation='softmax')(final_x)\n",
        "\n",
        "    # Define and Compile Model\n",
        "    model = Model(inputs=[image_input, quantum_input], outputs=output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-4),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Build and Train Model\n",
        "combined_model = build_combined_model()\n",
        "combined_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "huyiq7p54M4u",
        "outputId": "7a954802-551d-4deb-e82d-16cb4ea3aae8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Image_Input         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block1_conv1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m1,792\u001b[0m │ Image_Input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block1_conv2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ block1_conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block1_pool         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ block1_conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block2_conv1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ block1_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block2_conv2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ block2_conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block2_pool         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ block2_conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block3_conv1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m295,168\u001b[0m │ block2_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block3_conv2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m590,080\u001b[0m │ block3_conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block3_conv3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │    \u001b[38;5;34m590,080\u001b[0m │ block3_conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block3_pool         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ block3_conv3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block4_conv1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m1,180,160\u001b[0m │ block3_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block4_conv2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m2,359,808\u001b[0m │ block4_conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block4_conv3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │  \u001b[38;5;34m2,359,808\u001b[0m │ block4_conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │ \u001b[38;5;34m512\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block4_pool         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ block4_conv3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block5_conv1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ block4_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block5_conv2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ block5_conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block5_conv3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ block5_conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2D\u001b[0m)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block5_pool         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ block5_conv3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ block5_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │  \u001b[38;5;34m2,097,408\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Quantum_Input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m576\u001b[0m │ Quantum_Input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m20,608\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ Image_Input         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block1_conv1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │ Image_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block1_conv2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ block1_conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block1_pool         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block1_conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block2_conv1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ block1_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block2_conv2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ block2_conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block2_pool         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block2_conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block3_conv1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ block2_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block3_conv2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ block3_conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block3_conv3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ block3_conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block3_pool         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block3_conv3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block4_conv1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ block3_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block4_conv2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ block4_conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block4_conv3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ block4_conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block4_pool         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block4_conv3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block5_conv1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ block4_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block5_conv2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ block5_conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block5_conv3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ block5_conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)            │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ block5_pool         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block5_conv3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ block5_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,408</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ Quantum_Input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │ Quantum_Input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,868,643\u001b[0m (64.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,868,643</span> (64.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,133,155\u001b[0m (57.73 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,133,155</span> (57.73 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,735,488\u001b[0m (6.62 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,735,488</span> (6.62 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "train_inputs = {\"Image_Input\": X_train, \"Quantum_Input\": X_train_q}\n",
        "test_inputs = {\"Image_Input\": X_test, \"Quantum_Input\": X_test_q}\n",
        "\n",
        "history = combined_model.fit(\n",
        "    train_inputs, y_train,\n",
        "    validation_data=(test_inputs, y_test),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[reduce_lr],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLh4EJMH4uup",
        "outputId": "6b9bd73d-7c77-436c-ece2-8466709a7379"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 270ms/step - accuracy: 0.5374 - loss: 0.9541 - val_accuracy: 0.7455 - val_loss: 0.6611 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 113ms/step - accuracy: 0.8353 - loss: 0.4322 - val_accuracy: 0.8483 - val_loss: 0.3673 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - accuracy: 0.8643 - loss: 0.3568 - val_accuracy: 0.9054 - val_loss: 0.2992 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.9166 - loss: 0.2202 - val_accuracy: 0.9054 - val_loss: 0.2747 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 0.9372 - loss: 0.1643 - val_accuracy: 0.9396 - val_loss: 0.1970 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - accuracy: 0.9621 - loss: 0.1166 - val_accuracy: 0.9478 - val_loss: 0.1796 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 119ms/step - accuracy: 0.9786 - loss: 0.0604 - val_accuracy: 0.9560 - val_loss: 0.1466 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 0.9841 - loss: 0.0596 - val_accuracy: 0.9543 - val_loss: 0.1545 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 0.9839 - loss: 0.0638 - val_accuracy: 0.9690 - val_loss: 0.1105 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 120ms/step - accuracy: 0.9958 - loss: 0.0160 - val_accuracy: 0.9119 - val_loss: 0.5289 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.9792 - loss: 0.0736 - val_accuracy: 0.9641 - val_loss: 0.1826 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 0.9906 - loss: 0.0292 - val_accuracy: 0.9478 - val_loss: 0.3179 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.9833 - loss: 0.0589 - val_accuracy: 0.9413 - val_loss: 0.2739 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.9902 - loss: 0.0291 - val_accuracy: 0.9641 - val_loss: 0.2178 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 0.9641 - val_loss: 0.1775 - learning_rate: 5.0000e-05\n",
            "Epoch 16/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9739 - val_loss: 0.1987 - learning_rate: 5.0000e-05\n",
            "Epoch 17/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 6.9857e-04 - val_accuracy: 0.9739 - val_loss: 0.2070 - learning_rate: 5.0000e-05\n",
            "Epoch 18/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 4.1129e-04 - val_accuracy: 0.9723 - val_loss: 0.2174 - learning_rate: 5.0000e-05\n",
            "Epoch 19/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 0.9999 - loss: 7.1759e-04 - val_accuracy: 0.9690 - val_loss: 0.2159 - learning_rate: 5.0000e-05\n",
            "Epoch 20/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 4.1458e-04 - val_accuracy: 0.9706 - val_loss: 0.2281 - learning_rate: 2.5000e-05\n",
            "Epoch 21/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 2.4655e-04 - val_accuracy: 0.9706 - val_loss: 0.2342 - learning_rate: 2.5000e-05\n",
            "Epoch 22/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9690 - val_loss: 0.2209 - learning_rate: 2.5000e-05\n",
            "Epoch 23/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.9743e-04 - val_accuracy: 0.9706 - val_loss: 0.2257 - learning_rate: 2.5000e-05\n",
            "Epoch 24/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 3.0494e-04 - val_accuracy: 0.9706 - val_loss: 0.2313 - learning_rate: 2.5000e-05\n",
            "Epoch 25/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 2.4128e-04 - val_accuracy: 0.9706 - val_loss: 0.2342 - learning_rate: 1.2500e-05\n",
            "Epoch 26/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 4.9673e-04 - val_accuracy: 0.9690 - val_loss: 0.2386 - learning_rate: 1.2500e-05\n",
            "Epoch 27/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 3.1338e-04 - val_accuracy: 0.9690 - val_loss: 0.2414 - learning_rate: 1.2500e-05\n",
            "Epoch 28/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.0515e-04 - val_accuracy: 0.9690 - val_loss: 0.2426 - learning_rate: 1.2500e-05\n",
            "Epoch 29/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 3.5531e-04 - val_accuracy: 0.9690 - val_loss: 0.2482 - learning_rate: 1.2500e-05\n",
            "Epoch 30/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 2.3028e-04 - val_accuracy: 0.9690 - val_loss: 0.2495 - learning_rate: 6.2500e-06\n",
            "Epoch 31/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.6910e-04 - val_accuracy: 0.9690 - val_loss: 0.2525 - learning_rate: 6.2500e-06\n",
            "Epoch 32/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.7301e-04 - val_accuracy: 0.9690 - val_loss: 0.2541 - learning_rate: 6.2500e-06\n",
            "Epoch 33/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 0.9994 - loss: 7.6326e-04 - val_accuracy: 0.9690 - val_loss: 0.2587 - learning_rate: 6.2500e-06\n",
            "Epoch 34/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 5.5815e-05 - val_accuracy: 0.9690 - val_loss: 0.2605 - learning_rate: 6.2500e-06\n",
            "Epoch 35/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 2.9447e-04 - val_accuracy: 0.9690 - val_loss: 0.2606 - learning_rate: 3.1250e-06\n",
            "Epoch 36/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.4365e-04 - val_accuracy: 0.9690 - val_loss: 0.2615 - learning_rate: 3.1250e-06\n",
            "Epoch 37/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 2.7322e-04 - val_accuracy: 0.9690 - val_loss: 0.2622 - learning_rate: 3.1250e-06\n",
            "Epoch 38/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 2.0738e-04 - val_accuracy: 0.9690 - val_loss: 0.2619 - learning_rate: 3.1250e-06\n",
            "Epoch 39/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.5733e-04 - val_accuracy: 0.9690 - val_loss: 0.2617 - learning_rate: 3.1250e-06\n",
            "Epoch 40/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.4068e-04 - val_accuracy: 0.9690 - val_loss: 0.2619 - learning_rate: 1.5625e-06\n",
            "Epoch 41/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.0688e-04 - val_accuracy: 0.9690 - val_loss: 0.2622 - learning_rate: 1.5625e-06\n",
            "Epoch 42/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.1875e-04 - val_accuracy: 0.9690 - val_loss: 0.2632 - learning_rate: 1.5625e-06\n",
            "Epoch 43/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 6.2542e-05 - val_accuracy: 0.9690 - val_loss: 0.2635 - learning_rate: 1.5625e-06\n",
            "Epoch 44/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 1.3667e-04 - val_accuracy: 0.9690 - val_loss: 0.2641 - learning_rate: 1.5625e-06\n",
            "Epoch 45/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.1000e-04 - val_accuracy: 0.9690 - val_loss: 0.2641 - learning_rate: 1.0000e-06\n",
            "Epoch 46/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.0526e-04 - val_accuracy: 0.9690 - val_loss: 0.2646 - learning_rate: 1.0000e-06\n",
            "Epoch 47/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 3.5466e-04 - val_accuracy: 0.9690 - val_loss: 0.2649 - learning_rate: 1.0000e-06\n",
            "Epoch 48/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 2.0647e-04 - val_accuracy: 0.9690 - val_loss: 0.2655 - learning_rate: 1.0000e-06\n",
            "Epoch 49/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 5.2753e-05 - val_accuracy: 0.9690 - val_loss: 0.2658 - learning_rate: 1.0000e-06\n",
            "Epoch 50/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 3.7190e-04 - val_accuracy: 0.9690 - val_loss: 0.2661 - learning_rate: 1.0000e-06\n",
            "Epoch 51/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 7.1909e-05 - val_accuracy: 0.9690 - val_loss: 0.2662 - learning_rate: 1.0000e-06\n",
            "Epoch 52/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 3.0310e-04 - val_accuracy: 0.9690 - val_loss: 0.2661 - learning_rate: 1.0000e-06\n",
            "Epoch 53/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 6.1124e-05 - val_accuracy: 0.9690 - val_loss: 0.2662 - learning_rate: 1.0000e-06\n",
            "Epoch 54/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.2426e-04 - val_accuracy: 0.9690 - val_loss: 0.2662 - learning_rate: 1.0000e-06\n",
            "Epoch 55/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.1166e-04 - val_accuracy: 0.9690 - val_loss: 0.2666 - learning_rate: 1.0000e-06\n",
            "Epoch 56/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.9997 - loss: 3.8443e-04 - val_accuracy: 0.9690 - val_loss: 0.2660 - learning_rate: 1.0000e-06\n",
            "Epoch 57/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.0968e-04 - val_accuracy: 0.9690 - val_loss: 0.2667 - learning_rate: 1.0000e-06\n",
            "Epoch 58/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 5.5161e-05 - val_accuracy: 0.9690 - val_loss: 0.2668 - learning_rate: 1.0000e-06\n",
            "Epoch 59/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9690 - val_loss: 0.2648 - learning_rate: 1.0000e-06\n",
            "Epoch 60/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 3.0121e-04 - val_accuracy: 0.9690 - val_loss: 0.2638 - learning_rate: 1.0000e-06\n",
            "Epoch 61/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.4307e-04 - val_accuracy: 0.9690 - val_loss: 0.2645 - learning_rate: 1.0000e-06\n",
            "Epoch 62/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.7955e-04 - val_accuracy: 0.9690 - val_loss: 0.2657 - learning_rate: 1.0000e-06\n",
            "Epoch 63/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.2569e-04 - val_accuracy: 0.9690 - val_loss: 0.2661 - learning_rate: 1.0000e-06\n",
            "Epoch 64/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 5.6295e-05 - val_accuracy: 0.9690 - val_loss: 0.2662 - learning_rate: 1.0000e-06\n",
            "Epoch 65/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 1.5350e-04 - val_accuracy: 0.9690 - val_loss: 0.2668 - learning_rate: 1.0000e-06\n",
            "Epoch 66/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.2996e-04 - val_accuracy: 0.9690 - val_loss: 0.2673 - learning_rate: 1.0000e-06\n",
            "Epoch 67/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.6254e-04 - val_accuracy: 0.9690 - val_loss: 0.2678 - learning_rate: 1.0000e-06\n",
            "Epoch 68/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 3.8750e-05 - val_accuracy: 0.9690 - val_loss: 0.2688 - learning_rate: 1.0000e-06\n",
            "Epoch 69/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 5.4867e-05 - val_accuracy: 0.9690 - val_loss: 0.2696 - learning_rate: 1.0000e-06\n",
            "Epoch 70/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 5.4399e-05 - val_accuracy: 0.9690 - val_loss: 0.2705 - learning_rate: 1.0000e-06\n",
            "Epoch 71/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 2.7275e-05 - val_accuracy: 0.9690 - val_loss: 0.2711 - learning_rate: 1.0000e-06\n",
            "Epoch 72/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 7.9914e-05 - val_accuracy: 0.9690 - val_loss: 0.2717 - learning_rate: 1.0000e-06\n",
            "Epoch 73/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 4.8095e-05 - val_accuracy: 0.9690 - val_loss: 0.2731 - learning_rate: 1.0000e-06\n",
            "Epoch 74/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 4.8649e-05 - val_accuracy: 0.9690 - val_loss: 0.2738 - learning_rate: 1.0000e-06\n",
            "Epoch 75/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.2698e-04 - val_accuracy: 0.9690 - val_loss: 0.2749 - learning_rate: 1.0000e-06\n",
            "Epoch 76/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 0.9997 - loss: 4.2613e-04 - val_accuracy: 0.9690 - val_loss: 0.2738 - learning_rate: 1.0000e-06\n",
            "Epoch 77/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 2.6538e-05 - val_accuracy: 0.9690 - val_loss: 0.2738 - learning_rate: 1.0000e-06\n",
            "Epoch 78/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 6.0061e-05 - val_accuracy: 0.9690 - val_loss: 0.2744 - learning_rate: 1.0000e-06\n",
            "Epoch 79/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 1.0287e-04 - val_accuracy: 0.9690 - val_loss: 0.2748 - learning_rate: 1.0000e-06\n",
            "Epoch 80/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 2.2618e-05 - val_accuracy: 0.9690 - val_loss: 0.2750 - learning_rate: 1.0000e-06\n",
            "Epoch 81/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 6.2187e-05 - val_accuracy: 0.9690 - val_loss: 0.2755 - learning_rate: 1.0000e-06\n",
            "Epoch 82/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.6540e-04 - val_accuracy: 0.9690 - val_loss: 0.2766 - learning_rate: 1.0000e-06\n",
            "Epoch 83/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 2.0932e-05 - val_accuracy: 0.9690 - val_loss: 0.2771 - learning_rate: 1.0000e-06\n",
            "Epoch 84/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 9.6471e-05 - val_accuracy: 0.9690 - val_loss: 0.2779 - learning_rate: 1.0000e-06\n",
            "Epoch 85/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 3.7040e-05 - val_accuracy: 0.9690 - val_loss: 0.2784 - learning_rate: 1.0000e-06\n",
            "Epoch 86/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 4.6313e-05 - val_accuracy: 0.9690 - val_loss: 0.2796 - learning_rate: 1.0000e-06\n",
            "Epoch 87/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 5.6413e-05 - val_accuracy: 0.9690 - val_loss: 0.2799 - learning_rate: 1.0000e-06\n",
            "Epoch 88/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 2.0820e-05 - val_accuracy: 0.9690 - val_loss: 0.2808 - learning_rate: 1.0000e-06\n",
            "Epoch 89/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 3.2961e-05 - val_accuracy: 0.9690 - val_loss: 0.2809 - learning_rate: 1.0000e-06\n",
            "Epoch 90/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.9996 - loss: 6.5391e-04 - val_accuracy: 0.9690 - val_loss: 0.2776 - learning_rate: 1.0000e-06\n",
            "Epoch 91/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 2.0045e-05 - val_accuracy: 0.9690 - val_loss: 0.2775 - learning_rate: 1.0000e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 3.9902e-05 - val_accuracy: 0.9690 - val_loss: 0.2779 - learning_rate: 1.0000e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 8.4472e-05 - val_accuracy: 0.9690 - val_loss: 0.2795 - learning_rate: 1.0000e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.3098e-04 - val_accuracy: 0.9690 - val_loss: 0.2843 - learning_rate: 1.0000e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.4915e-04 - val_accuracy: 0.9690 - val_loss: 0.2851 - learning_rate: 1.0000e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 6.6607e-05 - val_accuracy: 0.9690 - val_loss: 0.2852 - learning_rate: 1.0000e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 1.4865e-04 - val_accuracy: 0.9706 - val_loss: 0.2892 - learning_rate: 1.0000e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 3.2730e-04 - val_accuracy: 0.9706 - val_loss: 0.2915 - learning_rate: 1.0000e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 119ms/step - accuracy: 0.9988 - loss: 0.0023 - val_accuracy: 0.9706 - val_loss: 0.2878 - learning_rate: 1.0000e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 118ms/step - accuracy: 0.9999 - loss: 3.6695e-04 - val_accuracy: 0.9723 - val_loss: 0.2829 - learning_rate: 1.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "test_loss, test_accuracy = combined_model.evaluate(test_inputs, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Classification Report\n",
        "y_pred = combined_model.predict(test_inputs)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(classification_report(y_test_labels, y_pred_labels, target_names=['Meningioma', 'Glioma', 'Pituitary Tumor']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2EHO0a65hEP",
        "outputId": "0262278f-4893-4ad6-fa98-22a4467f9639"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9623 - loss: 0.3748\n",
            "Test Accuracy: 0.9723\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     Meningioma       0.97      0.93      0.95       149\n",
            "         Glioma       0.97      0.99      0.98       286\n",
            "Pituitary Tumor       0.98      0.98      0.98       178\n",
            "\n",
            "       accuracy                           0.97       613\n",
            "      macro avg       0.97      0.97      0.97       613\n",
            "   weighted avg       0.97      0.97      0.97       613\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Meningioma', 'Glioma', 'Pituitary Tumor'])\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "5mzuWxnd5pch",
        "outputId": "92fd79de-afd6-4803-e64f-c9184ac0ab48"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "model_save_path = \"/content/combined_vgg16_quantum_model.h5\"\n",
        "combined_model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "id": "PFOTkm7c50gn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}